{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=1moaGNpmZjjN0XH0dcTOybEz8NVS00x-6'\n",
        "output = 'train_dataset.txt'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=19ajg9r-QMvDBuVDxBne4Y-vIzSqauAHS'\n",
        "output = 'test_dataset.txt'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teYE5-I2J09V",
        "outputId": "231ae9cc-4c18-4d92-a11d-64b37647314b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1moaGNpmZjjN0XH0dcTOybEz8NVS00x-6\n",
            "To: /content/train_dataset.txt\n",
            "100%|██████████| 17.0M/17.0M [00:00<00:00, 135MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=19ajg9r-QMvDBuVDxBne4Y-vIzSqauAHS\n",
            "To: /content/test_dataset.txt\n",
            "100%|██████████| 4.25M/4.25M [00:00<00:00, 185MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test_dataset.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "num_records = 0\n",
        "record = []\n",
        "with open('train_dataset.txt', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file, delimiter='\\t', quoting=csv.QUOTE_ALL, quotechar='\"')\n",
        "    next(reader) # Skip the first line\n",
        "    for row in reader:\n",
        "        if len(row) == 4:\n",
        "\n",
        "            record.append(row)"
      ],
      "metadata": {
        "id": "vKZLXt4MNv4O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(record))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAcfkeR4Nxdc",
        "outputId": "829ed03d-d1f0-4778-e747-ccc4c9184f05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique users and items\n",
        "unique_users = list(set([row[0] for row in record]))\n",
        "unique_items = list(set([row[1] for row in record]))\n",
        "\n",
        "# Create mappings from user_id and item_id to row and column indices\n",
        "user_mapping = {user: index for index, user in enumerate(unique_users)}\n",
        "item_mapping = {item: index for index, item in enumerate(unique_items)}\n",
        "\n",
        "# Map user_id and item_id to row and column indices\n",
        "record = [[user_mapping[row[0]], item_mapping[row[1]], row[2], row[3]] for row in record]\n",
        "\n",
        "# Separate the ratings and review texts\n",
        "ratings = [float(row[2]) for row in record]\n",
        "\n",
        "# Create a sparse matrix for the ratings\n",
        "r = csr_matrix((ratings, ([record[i][0] for i in range(len(record))], [record[i][1] for i in range(len(record))])))\n",
        "R_matrix = r.toarray()\n",
        "print(f'Number of records: {num_records}')\n",
        "print(f'R matrix: \\n{R_matrix}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SLV1uUPNTrs",
        "outputId": "c8823133-dc5e-4210-a2ac-ab7f3464a7f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of records: 0\n",
            "R matrix: \n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(r)\n",
        "print(R_matrix.size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx66y2vbHdux",
        "outputId": "8eb6600e-2763-40b3-b73a-c559de450d7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 131)\t1.0\n",
            "  (0, 167)\t1.0\n",
            "  (0, 176)\t1.0\n",
            "  (0, 181)\t1.0\n",
            "  (0, 187)\t1.0\n",
            "  (0, 188)\t1.0\n",
            "  (0, 218)\t1.0\n",
            "  (0, 234)\t1.0\n",
            "  (0, 293)\t1.0\n",
            "  (0, 308)\t1.0\n",
            "  (0, 312)\t1.0\n",
            "  (0, 359)\t1.0\n",
            "  (0, 364)\t1.0\n",
            "  (0, 416)\t1.0\n",
            "  (0, 423)\t1.0\n",
            "  (0, 434)\t1.0\n",
            "  (0, 452)\t1.0\n",
            "  (0, 488)\t1.0\n",
            "  (0, 498)\t1.0\n",
            "  (0, 511)\t1.0\n",
            "  (0, 541)\t1.0\n",
            "  (0, 548)\t1.0\n",
            "  (0, 573)\t1.0\n",
            "  (0, 581)\t1.0\n",
            "  (0, 585)\t1.0\n",
            "  :\t:\n",
            "  (1338, 666)\t1.0\n",
            "  (1338, 724)\t1.0\n",
            "  (1339, 4)\t1.0\n",
            "  (1339, 10)\t1.0\n",
            "  (1339, 64)\t1.0\n",
            "  (1339, 119)\t1.0\n",
            "  (1339, 124)\t1.0\n",
            "  (1339, 141)\t1.0\n",
            "  (1339, 150)\t1.0\n",
            "  (1339, 154)\t1.0\n",
            "  (1339, 196)\t1.0\n",
            "  (1339, 201)\t1.0\n",
            "  (1339, 216)\t1.0\n",
            "  (1339, 253)\t1.0\n",
            "  (1339, 300)\t1.0\n",
            "  (1339, 391)\t1.0\n",
            "  (1339, 440)\t1.0\n",
            "  (1339, 441)\t1.0\n",
            "  (1339, 450)\t1.0\n",
            "  (1339, 508)\t1.0\n",
            "  (1339, 509)\t1.0\n",
            "  (1339, 531)\t1.0\n",
            "  (1339, 572)\t1.0\n",
            "  (1339, 610)\t1.0\n",
            "  (1339, 689)\t1.0\n",
            "982220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(unique_users))\n",
        "print(len(unique_items))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m9CRkCROZfY",
        "outputId": "287d4809-c5a7-4633-f8f8-559eca53c9a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1340\n",
            "733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5TZMw4CAAUx",
        "outputId": "fe00fde4-8c66-404a-e617-2e19b66c8459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23038\n"
          ]
        }
      ],
      "source": [
        "print(len(record))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rXxpTvFP5xte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3dd3ab9-e663-4514-de4e-81336b2542ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(R_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load  BERT model**"
      ],
      "metadata": {
        "id": "MvwlBcX6XWbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LIx9eYBWCS2",
        "outputId": "f9c39df2-08b3-40cf-c38f-a0a3b75e165d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1eaa5aa21e8c4d62843866ad4f700172"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a95be4af919149bc844e9352f5ae7836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a7b10c5f9e8440e9997bc12d97990cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd55eb0800fd405788335cf944412066"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d304a38003544d728969b253d14d1497"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**:**\n"
      ],
      "metadata": {
        "id": "WmRdimXoW9Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract the review texts from the record\n",
        "\n",
        "reviews = [row[3] for row in record]\n"
      ],
      "metadata": {
        "id": "i1uhnr1AW672"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generate embeddings**"
      ],
      "metadata": {
        "id": "_gxJ58k31GIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "item_ids = [row[1] for row in record]\n",
        "item_embeddings = {}\n",
        "for item_id in tqdm(set(item_ids)):\n",
        "    # Get the indices of the reviews that belong to the current item\n",
        "    review_indices = [i for i, id in enumerate(item_ids) if id == item_id]\n",
        "    # Get the review texts that belong to the current item\n",
        "    item_reviews = [reviews[i] for i in review_indices]\n",
        "    # Tokenize the review texts and convert them to tensors\n",
        "    inputs = tokenizer(item_reviews, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "\n",
        "    # embedding for each review\n",
        "    review_embeddings  = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "    # average of the embeddings for the current item\n",
        "    item_embeddings[item_id] = review_embeddings.mean(dim=0)\n",
        "    del inputs, outputs\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LA_ReIhYfTP",
        "outputId": "bb331500-85a5-43a4-c046-281f9dbd1168"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 733/733 [12:58<00:00,  1.06s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the item embeddings for next parts\n",
        "\n",
        "torch.save(item_embeddings, 'item_embeddings.pt')"
      ],
      "metadata": {
        "id": "SZI3_Upu5YfD"
      },
      "execution_count": 13,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}